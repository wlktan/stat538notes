\documentclass[10pt]{article}
\usepackage{fullpage, amsmath, amsthm, amsfonts}
\usepackage{natbib}

%\usepackage{epsfig}

\newcommand{\Ex}[2]{\mathop{\mathbb{E}}\displaylimits_{#1}\left
[ #2 \right ]}
\newcommand{\Expect}[1]{\mathop{\mathbb{E}}\left
[ #1 \right ]}


%---------- Commands ---------------% 
\newcommand\textbox[1]{\parbox{.5\textwidth}{#1}}
\newcommand\longtxt[1]{\parbox{.8\textwidth}{#1}}
 \newcommand\shorttxt[1]{\parbox{.2\textwidth}{#1}}
 \newcommand\ben{\begin{enumerate}}
 \newcommand\een{\end{enumerate}}
  \newcommand\beq{\begin{eqnarray*}}
 \newcommand\eeq{\end{eqnarray*}}
   \newcommand\bal{\begin{aligned}}
 \newcommand\eal{\end{aligned}}
  \newcommand\bi{\begin{itemize}}
 \newcommand\ei{\end{itemize}}
\newcommand{\sumi}{\sum\limits_{i=1}^n}
\newcommand{\sumj}{\sum\limits_{j=1}^{n_i}}
\newcommand{\sumt}{\sum\limits_{t=0}^1}
\newcommand{\sumd}{\sum\limits_{d=0}^1}
\newcommand{\muli}{\Pi_{i=1}^n}
\newcommand{\mulj}{\Pi_{j=1}^{n_i}}

 \newcommand{\itab}[1]{\hspace{0em}\rlap{#1}}
\newcommand{\tab}[1]{\hspace{.05\textwidth}\rlap{#1}}




\begin{document}
\input{preamble.tex}

\lecture{1}{}{Zaid Harchaoui}{Katherine Tan, Jiacheng Wu}%Replace "Jyn Erso" by your name(s)


%%%% body goes in here %%%%
\section{General framework}
\noindent Last time, we considered the optimization problem

\[
\underset{x \in \mathbb{R}^p}{min} F(x) = f(x) + \psi(x)\]

\noindent where $f(.)$ is convex with Lipschitz constant $L$, and $\psi(.)$ is convex but may not be differentiable. Typically, $f(x)$ is a sum of loss functions evaluated at each data point, and $\psi(x)$ serves as a regularizer/penalty. For example, in Logistic Regression:

\[
\underset{x \in \mathbb{R}^p}{min} \dfrac{1}{n} \sumi log(1 + e^{-y_i x^T a_i}) + \lambda ||x||_1
\]

\noindent where $f(x) = \dfrac{1}{n} \sumi log(1 + e^{-y_i x^T a_i})$, $\psi(x) = \lambda ||x||_1$. These problems can be solved through first-order optimization problems, such as gradient descent and coordinate descent.

\noindent  \textit{Question} Consider an algorithm $\mathbb{A}$ that $\epsilon$-minimizes $G$ (i.e. minimizes $G$ with rate $O(\frac{1}{\epsilon})$. Can we engineer an algorithm $\mathbb{A^*}$ with rate $O(\frac{1}{\epsilon^2})$ (or in general a faster algorithm)?

\noindent \textit{Answer}: \texttt{Catalyst} algorithm \citep{lin2015universal}.

\section{Catalyst}
\noindent The idea of the \texttt{Catalyst} algorithm is based on an auxiliary objective function:

\[
\underset{x \in \mathbb{R}^p}{min} G(x) = f(x) + \dfrac{K}{2} ||x-y||_2^2\]

\bi
\item In convex analysis, this formulation is also known as:
\bi
\item Moreau envelope
\item Moreau-Yosida regularization smoothing
\ei

\item $K$ is a constant that will be specified later.


\item Notes on \textit{condition numbers}:
\bi
\item The condition number of $F$ is $\tau_F = \dfrac{\mu}{L}$ (where $\mu$ is the strong convexity parameter and $L$ is the Lipschitz constant).
\item The condition number of the new function G is $\tau_G = \dfrac{\mu + K}{L + K}$
\ei

\item Relationships between $K$, condition numbers and objective functions:
\bi
\item If $K <<< 1$, $\tau_G \approx \tau_F$.
\item If $K$ is large, $G \approx \dfrac{K}{2} ||x-y||_2^2$
\ei

\item  $\mathbb{A}$ denotes $\epsilon$-minimize $G(x)$ and $\mathbb{A}^*$ denotes the catalyst version

\ei

\noindent \textit{Catalyst} algorithm:\\

\noindent \textit{INPUT} Initial estimate $x_0 \in \mathbb{R}^p$, parameters $K$ and $\alpha_0$, sequence $\epsilon_t, t \geq 0$.
\bi
\item Initialize $q = \dfrac{\mu}{\mu + K}$, $y_0 = x_0$.
\item Run iteration $t=1,\hdots$ (until stopping criterion)
\bi
\item $x_t = \epsilon_k - \underset{x}{\text{argmin}} G_k(x) = F(x) + \dfrac{K}{2} \|x-y_{k-1}\|_2^2$.
\item $y_t = x_t + \beta_k(x_t - x_{t-1})$.
\ei
\noindent where $\beta_t = \dfrac{\alpha_{t-1}(1-\alpha_{t-1})}{\alpha_{t-1}^2 + \alpha_{t}}$, $\alpha_t \in [0,1]$ such that $\alpha_t^2 = (1-\alpha_t)\alpha_{t-1}^2 + q \alpha_t$.
\ei
\noindent \textit{OUTPUT} Final estimates $x_t$.\\

\section{Convergence Analysis}


\bi
\item When $F$ is $\mu$ strongly convex:
\ei

Define $\epsilon_t = C[F(x_0) - F^*](1-\rho)^t$, $\rho < \dfrac{\mu}{\mu + K}$. Then $\mathbb{A}^*$ generates $(x_t)_{t\geq0}$ such that

\[
F(x_t) - F^* \leq C(1-\rho)^{t+1}(F(x_0) - F^*)
\]

\bi
\item When $F$ is $\mu$ is convex (but not strongly convex):
\ei

Define $\epsilon_t = C \dfrac{F(x_0) - F^*}{(K+2)^5}$. Then $\mathbb{A}^*$ generates $(x_t)_{t\geq0}$ such that

\[
F(x_t) - F^* \leq \dfrac{C}{(K+2)^2} \left( C(F(x_0) - F^*) + \dfrac{K}{2} ||x_0 - x^*||_2^2 \right)
\]

\noindent This means that:

\bi
\item For an algorithm $\mathbb{A}$ that $\epsilon$ minimizes $G$ with rate $O(\frac{1}{t})$ in terms of number of iterations (i.e. is $O(\frac{1}{\epsilon})$ in terms of accuracy if $\dfrac{LD^2}{t+1} = \epsilon$.
\item \textit{Catalyst} action for accelerated $\mathbb{A}^*$ results in rate $O(\frac{1}{K^2})$ = $O(\frac{1}{\sqrt{\epsilon}})$
\ei


\section{User-guide Generic Acceleration}
We going to minimize a smooth function plus a convex function that may not be differentiable. For example, 
\[
G(x) = \underbrace{-l(x)}_{\text{logistic loss}} + \underbrace{\lambda_1 \|x\|_1 + \lambda_2 \|x\|_2^2}_{\text{elastic net penalty}}
\]
The convergence rate of an accelerated algorithm $\mathbb{A}$ is driven by the parameter $K$. The bet choice is to maximize the following
\bi
\item Strongly convex case 
\[
\text{Max} \frac{\tau_{A, G_k}}{\sqrt{\mu+K}}
\]

\item Non-strongly convex case
\[
\text{Max} \frac{\tau_{A, G_k}}{\sqrt{L+K}}
\]
\ei


\bibliographystyle{agsm}
\bibliography{note}

\end{document}
