\documentclass[12pt]{article}

%------------ Dimensions -------------%
\usepackage[
top    = 1in,
bottom = 1in,
left   = 1in,
right  = 1in]{geometry}

%-------------- Header and footer customization -----------%
 \usepackage{fancyhdr, adjustbox, setspace, amsmath,multirow,natbib,caption,subcaption, titling, amssymb}
\pagestyle{fancy}
 \lhead{}
 \chead{}
 \rhead{}
 \lfoot{}
 \rfoot{}

%---------- Commands ---------------% 
\newcommand\textbox[1]{\parbox{.5\textwidth}{#1}}
\newcommand\longtxt[1]{\parbox{.8\textwidth}{#1}}
 \newcommand\shorttxt[1]{\parbox{.2\textwidth}{#1}}
 \newcommand\ben{\begin{enumerate}}
 \newcommand\een{\end{enumerate}}
  \newcommand\beq{\begin{eqnarray*}}
 \newcommand\eeq{\end{eqnarray*}}
   \newcommand\bal{\begin{aligned}}
 \newcommand\eal{\end{aligned}}
  \newcommand\bi{\begin{itemize}}
 \newcommand\ei{\end{itemize}}
\newcommand{\sumi}{\sum\limits_{i=1}^n}
\newcommand{\sumj}{\sum\limits_{j=1}^{n_i}}
\newcommand{\sumt}{\sum\limits_{t=0}^1}
\newcommand{\sumd}{\sum\limits_{d=0}^1}
\newcommand{\muli}{\Pi_{i=1}^n}
\newcommand{\mulj}{\Pi_{j=1}^{n_i}}
 \bibliographystyle{plainnat}
 \newcommand{\itab}[1]{\hspace{0em}\rlap{#1}}
\newcommand{\tab}[1]{\hspace{.05\textwidth}\rlap{#1}}
\bibliographystyle{plainnat}


\begin{document}
\title{STAT 538 Lecture 7 (Jan 24 2017)}
\maketitle

\noindent Last time, we considered the optimization problem

\[
\underset{x \in \mathbb{R}^p}{min} F(x) = f(x) + \psi(x)\]

\noindent where $f(.)$ is convex with Lipschitz constant $L$, and $\psi(.)$ is convex but may not be differentiable. Typically, $f(x)$ is a sum of loss functions evaluated at each data point, and $\psi(x)$ serves as a regularizer/penalty. For example, in Logistic Regression:

\[
\underset{x \in \mathbb{R}^p}{min} \dfrac{1}{n} \sumi log(1 + e^{-y_i x^T a_i}) + \lambda ||x||_1
\]

\noindent where $f(x) = \dfrac{1}{n} \sumi log(1 + e^{-y_i x^T a_i})$, $\psi(x) = \lambda ||x||_1$. These problems can be solved through first-order optimization problems, such as gradient descent and coordinate descent.

\noindent  \textit{Question} Consider an algorithm $\mathbb{A}$ that $\epsilon$-minimizes $G$ (i.e. minimizes $G$ with rate $O(\frac{1}{\epsilon})$. Can we engineer an algorithm $\mathbb{A^*}$ with rate $O(\frac{1}{\epsilon^2})$ (or in general a faster algorithm)?

\noindent \textit{Answer}: \texttt{Catalyst} algorithm (Lin, Mairal, Harchaoui 2015).\\

\noindent The idea of the \texttt{Catalyst} algorithm is based on an auxiliary objective function:

\[
\underset{x \in \mathbb{R}^p}{min} G(x) = f(x) + \dfrac{K}{2} ||x-y||_2^2\]

\bi
\item In convex analysis, this formulation is also known as:
\bi
\item Moreau envelope
\item Moreau-Yosida regularization smoothing
\ei

\item $K$ is a constant that will be specified later.


\item Notes on \textit{condition numbers}:
\bi
\item The condition number of $F$ is $\tau_F = \dfrac{\mu}{L}$ (where $\mu$ is the strong convexity parameter and $L$ is the Lipschitz constant).
\item The condition number of the new function G is $\tau_G = \dfrac{\mu + K}{L + K}$
\ei

\item Relationships between $K$, condition numbers and objective functions:
\bi
\item If $K <<< 1$, $\tau_G \approx \tau_F$.
\item If $K$ is large, $G \approx \dfrac{K}{2} ||x-y||_2^2$
\ei
\ei

\noindent \textit{Catalyst} algorithm:\\

\noindent \textit{INPUT} Initial estimate $x_0 \in \mathbb{R}^p$, parameters $K$ and $\alpha_0$, sequence $\epsilon_t, t \geq 0$.
\bi
\item Initialize $q = \dfrac{\mu}{\mu + K}$, $y_0 = x_0$.
\item Run iteration $t=1,\hdots$ (until stopping criterion)
\bi
\item $x_t = \underset{x}{\epsilon_k argmin} G_k(x) = F(x) + \dfrac{K}{2} ||x-y||_2^2$.
\item $y_t = x_t + \beta_k(x_t - x_{t-1})$.
\ei
\noindent where $\beta_t = \dfrac{\alpha_{t-1}(1-\alpha_{t-1})}{\alpha_{t-1}^2 + \alpha_{t}}$, $\alpha_t \in [0,1]$ such that $\alpha_t^2 = (1-\alpha_t)\alpha_{t-1}^2 + q \alpha_t$.
\ei
\noindent \textit{OUTPUT} Final estimates $x_t$.\\

\noindent Convergence when $F$ is $\mu$ strongly convex:\\
\noindent Define $\epsilon_t = C[F(x_0) - F^*](1-\rho)^t$, $\rho < \dfrac{\mu}{\mu + K}$. Then $\mathbb{A}^*$ generates $(x_t)_{t\geq0}$ such that

\[
F(x_t) - F^* \leq C(1-\rho)^{t+1}(F(x_0) - F^*)
\]

\noindent  Convergence when $F$ is $\mu$ is convex (but not strongly convex):\\
\noindent Define $\epsilon_t = C \dfrac{F(x_0) - F^*}{(K+2)^5}$. Then $\mathbb{A}^*$ generates $(x_t)_{t\geq0}$ such that

\[
F(x_t) - F^* \leq \dfrac{C}{(K+2)^2} \left( C(F(x_0) - F^*) + \dfrac{K}{2} ||x_0 - x^*||_2^2 \right)
\]

\noindent This means that:

\bi
\item For an algorithm $\mathbb{A}$ that $\epsilon$ minimizes $G$ with rate $O(\frac{1}{t})$ in terms of number of iterations (i.e. is $O(\frac{1}{\epsilon})$ in terms of accuracy if $\dfrac{LD^2}{t+1} = \epsilon$.
\item \textit{Catalyst} action for accelerated $\mathbb{A}^*$ results in rate $O(\frac{1}{K^2})$ = $O(\frac{1}{\sqrt{\epsilon}})$
\ei

\end{document}
